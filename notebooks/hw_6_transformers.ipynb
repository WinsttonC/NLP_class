{"cells":[{"cell_type":"markdown","metadata":{"id":"rB0Vt_fxdvQ9"},"source":["### Импорты"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DWwctZGoWfu_"},"outputs":[],"source":["!pip install transformers\n","!pip install datasets\n","!pip install evaluate\n","!pip install -U accelerate"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13064,"status":"ok","timestamp":1699957019133,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"QTZuw0pFlmX-"},"outputs":[],"source":["import torch\n","import evaluate\n","import numpy as np\n","from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from datasets import load_dataset\n","from transformers import AutoTokenizer\n","from transformers import DataCollatorWithPadding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0M8oSLoWPjO"},"outputs":[],"source":["checkpoint = \"cardiffnlp/twitter-roberta-base-sentiment\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n","sequences = [\n","    \"I've been waiting for a HuggingFace course my whole life.\",\n","    \"This course is amazing!\",\n","]\n","batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","batch[\"labels\"] = torch.tensor([1, 1])\n","\n","optimizer = AdamW(model.parameters())\n","loss = model(**batch).loss\n","loss.backward()\n","optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"-tatqakQd2hp"},"source":["### Предобработка"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"orZBOvt2gkyu"},"outputs":[],"source":["raw_datasets = load_dataset('tyqiangz/multilingual-sentiments', 'english')\n","def change_labels(example):\n","    if example['label'] == 0:\n","        example['label'] = 2\n","    elif example['label'] == 2:\n","        example['label'] = 0\n","    return example\n","\n","raw_datasets = raw_datasets.map(change_labels)\n","raw_datasets['train'][0:3]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1339,"status":"ok","timestamp":1699957037312,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"KYCV8-q1km0U"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","tokenized_sentences_1 = tokenizer(raw_datasets[\"train\"][\"text\"])\n","tokenized_sentences_2 = tokenizer(raw_datasets[\"train\"][\"text\"])"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":47,"status":"ok","timestamp":1699957037313,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"PXVs3YlQTZN1"},"outputs":[],"source":["def tokenize_function(example):\n","    return tokenizer(example[\"text\"], truncation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Jt8kHOFTbw6"},"outputs":[],"source":["tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n","tokenized_datasets"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1699957038180,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"2kIOyrlrTpMx"},"outputs":[],"source":["data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":480,"status":"ok","timestamp":1699957038652,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"-NGobtWDbLlg"},"outputs":[],"source":["training_args = TrainingArguments(\"test-trainer\")"]},{"cell_type":"markdown","metadata":{"id":"oxMqlDAsejz-"},"source":["### Обучение"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":10381,"status":"ok","timestamp":1699957049028,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"vlgYvpRHdp1t"},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Q40zB-hd2Jw"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OWxcE2Ngd4Ji"},"outputs":[],"source":["predictions = trainer.predict(tokenized_datasets[\"validation\"])\n","print(predictions.predictions.shape, predictions.label_ids.shape)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1699957130139,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"7SUhXEl6d6bN"},"outputs":[],"source":["preds = np.argmax(predictions.predictions, axis=-1)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3XN1x_a_dIzT"},"source":["### Черновик"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699957130139,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"PUMAxp4gd_gn"},"outputs":[],"source":["def compute_metrics(eval_preds):\n","    metric = evaluate.load('tyqiangz/multilingual-sentiments', 'english')\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","    return metric.compute(predictions=predictions, references=labels)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7914,"status":"ok","timestamp":1699957974481,"user":{"displayName":"Даниил Тимофеев","userId":"04200510345473215032"},"user_tz":-180},"id":"7mfx06zveBoZ"},"outputs":[],"source":["training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n","\n","trainer = Trainer(\n","    model,\n","    training_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPMeBEqCeEdG"},"outputs":[],"source":["trainer.train()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPHNKXGIU+MzMXCbdYauLVd","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
